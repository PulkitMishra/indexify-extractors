{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ee93b68-500e-4bef-9ecd-de05491861fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchvision is not available - cannot save figures\n",
      "[NeMo W 2024-03-22 13:50:17 nemo_logging:393] Could not import NeMo NLP collection which is required for speech translation model.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import whisperx\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f4ba0e-d53d-4938-9a1b-cad490ffabbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"audio\":\"/Users/lucasjackson/Workspace/tensorlake/test-files/podcast-short.mp3\",\n",
    "    \"language\":None,\n",
    "    \"stemming\":True,\n",
    "    \"batch_size\": 0,\n",
    "    \"model\":\"distil-medium.en\",\n",
    "    \"supress_numerals\": False,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04792cb8-e9c1-47e2-905b-1881161bd72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model is a bag of 1 models. You will see that many progress bars per track.\n",
      "Separated tracks will be stored in /Users/lucasjackson/Workspace/tensorlake/indexify-extractors/audio/whisper-diarization/temp_outputs/htdemucs\n",
      "Separating track /Users/lucasjackson/Workspace/tensorlake/test-files/podcast-short.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 35.099999999999994/35.099999999999994 [00:16<00:00,  2.07seconds/s]\n"
     ]
    }
   ],
   "source": [
    "if params.get(\"stemming\"):\n",
    "    # Isolate vocals from the rest of the audio\n",
    "\n",
    "    return_code = os.system(\n",
    "        f'python3 -m demucs.separate -n htdemucs --two-stems=vocals \"{params.get(\"audio\")}\" -o \"temp_outputs\"'\n",
    "    )\n",
    "\n",
    "    if return_code != 0:\n",
    "        logging.warning(\n",
    "            \"Source splitting failed, using original audio file. Use --no-stem argument to disable it.\"\n",
    "        )\n",
    "        vocal_target = params.get(\"audio\")\n",
    "    else:\n",
    "        vocal_target = os.path.join(\n",
    "            \"temp_outputs\",\n",
    "            \"htdemucs\",\n",
    "            os.path.splitext(os.path.basename(params.get(\"audio\")))[0],\n",
    "            \"vocals.wav\",\n",
    "        )\n",
    "else:\n",
    "    vocal_target = params.get(\"audio\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c8f00e-d3e0-41c8-a26c-b184dfd9ef5a",
   "metadata": {},
   "source": [
    "# Get whisper results and language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ccea44-b63b-4793-9520-a8dfa12aa70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtypes = {\"cpu\": \"int8\", \"cuda\": \"float16\"}\n",
    "\n",
    "if params.get(\"batch_size\") != 0:\n",
    "    from transcription_helpers import transcribe_batched\n",
    "    whisper_results, language = transcribe(\n",
    "        vocal_target,\n",
    "        params.get(\"language\"),\n",
    "        params.get(\"batch_size\"),\n",
    "        params.get(\"model\"),\n",
    "        mtypes[params.get(\"device\")],\n",
    "        params.get(\"supress_numerals\"),\n",
    "        params.get(\"device\"),\n",
    "    )\n",
    "else:\n",
    "    from transcription_helpers import transcribe\n",
    "    whisper_results, language = transcribe(\n",
    "        vocal_target,\n",
    "        params.get(\"language\"),\n",
    "        params.get(\"model\"),\n",
    "        mtypes[params.get(\"device\")],\n",
    "        params.get(\"supress_numerals\"),\n",
    "        params.get(\"device\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7bd7af-6d8f-4ea3-aec1-9ce649ae6131",
   "metadata": {},
   "source": [
    "# word alignment to timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9adecc23-933e-4a7b-b182-a04342a38779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import wav2vec2_langs, filter_missing_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cbfbb05-2e43-4677-8f1a-d40def3ec853",
   "metadata": {},
   "outputs": [],
   "source": [
    "if language in wav2vec2_langs:\n",
    "    alignment_model, metadata = whisperx.load_align_model(\n",
    "        language_code=language, device=params.get(\"device\")\n",
    "    )\n",
    "    result_aligned = whisperx.align(\n",
    "        whisper_results, alignment_model, metadata, vocal_target, params.get(\"device\")\n",
    "    )\n",
    "    word_timestamps = filter_missing_timestamps(\n",
    "        result_aligned[\"word_segments\"],\n",
    "        initial_timestamp=whisper_results[0].get(\"start\"),\n",
    "        final_timestamp=whisper_results[-1].get(\"end\"),\n",
    "    )\n",
    "    # clear gpu vram\n",
    "    del alignment_model\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    assert (\n",
    "        params.get(\"batch_size\") == 0  # TODO: add a better check for word timestamps existence\n",
    "    ), (\n",
    "        f\"Unsupported language: {language}, use --batch_size to 0\"\n",
    "        \" to generate word timestamps using whisper directly and fix this error.\"\n",
    "    )\n",
    "    word_timestamps = []\n",
    "    for segment in whisper_results:\n",
    "        for word in segment[\"words\"]:\n",
    "            word_timestamps.append({\"word\": word[2], \"start\": word[0], \"end\": word[1]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f28698-d5d4-42c0-8ca1-198f3d4fd100",
   "metadata": {},
   "source": [
    "# Nemo process for automatic speech recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d9d83e3-2af5-4a2a-bfa0-a6a410d79a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-22 13:51:15 nemo_logging:381] Loading pretrained diar_msdd_telephonic model from NGC\n",
      "[NeMo I 2024-03-22 13:51:15 nemo_logging:381] Found existing object /Users/lucasjackson/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
      "[NeMo I 2024-03-22 13:51:15 nemo_logging:381] Re-using file from: /Users/lucasjackson/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
      "[NeMo I 2024-03-22 13:51:15 nemo_logging:381] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-03-22 13:51:15 nemo_logging:393] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: null\n",
      "    emb_dir: null\n",
      "    sample_rate: 16000\n",
      "    num_spks: 2\n",
      "    soft_label_thres: 0.5\n",
      "    labels: null\n",
      "    batch_size: 15\n",
      "    emb_batch_size: 0\n",
      "    shuffle: true\n",
      "    \n",
      "[NeMo W 2024-03-22 13:51:15 nemo_logging:393] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: null\n",
      "    emb_dir: null\n",
      "    sample_rate: 16000\n",
      "    num_spks: 2\n",
      "    soft_label_thres: 0.5\n",
      "    labels: null\n",
      "    batch_size: 15\n",
      "    emb_batch_size: 0\n",
      "    shuffle: false\n",
      "    \n",
      "[NeMo W 2024-03-22 13:51:15 nemo_logging:393] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    emb_dir: null\n",
      "    sample_rate: 16000\n",
      "    num_spks: 2\n",
      "    soft_label_thres: 0.5\n",
      "    labels: null\n",
      "    batch_size: 15\n",
      "    emb_batch_size: 0\n",
      "    shuffle: false\n",
      "    seq_eval_mode: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-22 13:51:15 nemo_logging:381] PADDING: 16\n",
      "[NeMo I 2024-03-22 13:51:16 nemo_logging:381] PADDING: 16\n",
      "[NeMo I 2024-03-22 13:51:16 nemo_logging:381] Model EncDecDiarLabelModel was successfully restored from /Users/lucasjackson/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
      "[NeMo I 2024-03-22 13:51:16 nemo_logging:381] PADDING: 16\n",
      "[NeMo I 2024-03-22 13:51:16 nemo_logging:381] Loading pretrained vad_multilingual_marblenet model from NGC\n",
      "[NeMo I 2024-03-22 13:51:16 nemo_logging:381] Found existing object /Users/lucasjackson/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
      "[NeMo I 2024-03-22 13:51:16 nemo_logging:381] Re-using file from: /Users/lucasjackson/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
      "[NeMo I 2024-03-22 13:51:16 nemo_logging:381] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-03-22 13:51:16 nemo_logging:393] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 256\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      shift:\n",
      "        prob: 0.5\n",
      "        min_shift_ms: -10.0\n",
      "        max_shift_ms: 10.0\n",
      "      white_noise:\n",
      "        prob: 0.5\n",
      "        min_level: -90\n",
      "        max_level: -46\n",
      "        norm: true\n",
      "      noise:\n",
      "        prob: 0.5\n",
      "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 30\n",
      "        max_gain_db: 300.0\n",
      "        norm: true\n",
      "      gain:\n",
      "        prob: 0.5\n",
      "        min_gain_dbfs: -10.0\n",
      "        max_gain_dbfs: 10.0\n",
      "        norm: true\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2024-03-22 13:51:16 nemo_logging:393] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 256\n",
      "    shuffle: false\n",
      "    val_loss_idx: 0\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2024-03-22 13:51:16 nemo_logging:393] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    test_loss_idx: 0\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-22 13:51:16 nemo_logging:381] PADDING: 16\n",
      "[NeMo I 2024-03-22 13:51:16 nemo_logging:381] Model EncDecClassificationModel was successfully restored from /Users/lucasjackson/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
      "[NeMo I 2024-03-22 13:51:16 nemo_logging:381] Multiscale Weights: [1, 1, 1, 1, 1]\n",
      "[NeMo I 2024-03-22 13:51:16 nemo_logging:381] Clustering Parameters: {\n",
      "        \"oracle_num_speakers\": false,\n",
      "        \"max_num_speakers\": 8,\n",
      "        \"enhanced_count_thres\": 80,\n",
      "        \"max_rp_threshold\": 0.25,\n",
      "        \"sparse_search_volume\": 30,\n",
      "        \"maj_vote_spk_count\": false\n",
      "    }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-03-22 13:51:16 nemo_logging:393] Deleting previous clustering diarizer outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-22 13:51:16 nemo_logging:381] Number of files to diarize: 1\n",
      "[NeMo I 2024-03-22 13:51:16 nemo_logging:381] Split long audio file to avoid CUDA memory issue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "splitting manifest: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-22 13:51:17 nemo_logging:381] The prepared manifest file exists. Overwriting!\n",
      "[NeMo I 2024-03-22 13:51:17 nemo_logging:381] Perform streaming frame-level VAD\n",
      "[NeMo I 2024-03-22 13:51:17 nemo_logging:381] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-03-22 13:51:17 nemo_logging:381] Dataset loaded with 1 items, total duration of  0.01 hours.\n",
      "[NeMo I 2024-03-22 13:51:17 nemo_logging:381] # 1 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "vad: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:11<00:00, 11.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-22 13:51:28 nemo_logging:381] Generating predictions with overlapping input segments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                                                                                                                                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-22 13:51:28 nemo_logging:381] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "creating speech segments: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 45.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-22 13:51:28 nemo_logging:381] Subsegmentation for embedding extraction: scale0, /Users/lucasjackson/Workspace/tensorlake/indexify-extractors/audio/whisper-diarization/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
      "[NeMo I 2024-03-22 13:51:28 nemo_logging:381] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-03-22 13:51:28 nemo_logging:381] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-03-22 13:51:28 nemo_logging:381] Dataset loaded with 31 items, total duration of  0.01 hours.\n",
      "[NeMo I 2024-03-22 13:51:28 nemo_logging:381] # 31 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/5] extract embeddings: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:26<00:00, 26.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-22 13:51:54 nemo_logging:381] Saved embedding files to /Users/lucasjackson/Workspace/tensorlake/indexify-extractors/audio/whisper-diarization/temp_outputs/speaker_outputs/embeddings\n",
      "[NeMo I 2024-03-22 13:51:54 nemo_logging:381] Subsegmentation for embedding extraction: scale1, /Users/lucasjackson/Workspace/tensorlake/indexify-extractors/audio/whisper-diarization/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
      "[NeMo I 2024-03-22 13:51:54 nemo_logging:381] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-03-22 13:51:54 nemo_logging:381] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-03-22 13:51:54 nemo_logging:381] Dataset loaded with 35 items, total duration of  0.01 hours.\n",
      "[NeMo I 2024-03-22 13:51:54 nemo_logging:381] # 35 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/5] extract embeddings: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:22<00:00, 22.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-22 13:52:17 nemo_logging:381] Saved embedding files to /Users/lucasjackson/Workspace/tensorlake/indexify-extractors/audio/whisper-diarization/temp_outputs/speaker_outputs/embeddings\n",
      "[NeMo I 2024-03-22 13:52:17 nemo_logging:381] Subsegmentation for embedding extraction: scale2, /Users/lucasjackson/Workspace/tensorlake/indexify-extractors/audio/whisper-diarization/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
      "[NeMo I 2024-03-22 13:52:17 nemo_logging:381] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-03-22 13:52:17 nemo_logging:381] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-03-22 13:52:17 nemo_logging:381] Dataset loaded with 42 items, total duration of  0.01 hours.\n",
      "[NeMo I 2024-03-22 13:52:17 nemo_logging:381] # 42 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/5] extract embeddings: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:23<00:00, 23.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-22 13:52:40 nemo_logging:381] Saved embedding files to /Users/lucasjackson/Workspace/tensorlake/indexify-extractors/audio/whisper-diarization/temp_outputs/speaker_outputs/embeddings\n",
      "[NeMo I 2024-03-22 13:52:40 nemo_logging:381] Subsegmentation for embedding extraction: scale3, /Users/lucasjackson/Workspace/tensorlake/indexify-extractors/audio/whisper-diarization/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
      "[NeMo I 2024-03-22 13:52:40 nemo_logging:381] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-03-22 13:52:40 nemo_logging:381] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-03-22 13:52:40 nemo_logging:381] Dataset loaded with 56 items, total duration of  0.01 hours.\n",
      "[NeMo I 2024-03-22 13:52:40 nemo_logging:381] # 56 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/5] extract embeddings: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:19<00:00, 19.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-22 13:53:00 nemo_logging:381] Saved embedding files to /Users/lucasjackson/Workspace/tensorlake/indexify-extractors/audio/whisper-diarization/temp_outputs/speaker_outputs/embeddings\n",
      "[NeMo I 2024-03-22 13:53:00 nemo_logging:381] Subsegmentation for embedding extraction: scale4, /Users/lucasjackson/Workspace/tensorlake/indexify-extractors/audio/whisper-diarization/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
      "[NeMo I 2024-03-22 13:53:00 nemo_logging:381] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-03-22 13:53:00 nemo_logging:381] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-03-22 13:53:00 nemo_logging:381] Dataset loaded with 85 items, total duration of  0.01 hours.\n",
      "[NeMo I 2024-03-22 13:53:00 nemo_logging:381] # 85 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/5] extract embeddings: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:27<00:00, 13.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-22 13:53:28 nemo_logging:381] Saved embedding files to /Users/lucasjackson/Workspace/tensorlake/indexify-extractors/audio/whisper-diarization/temp_outputs/speaker_outputs/embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2024-03-22 13:53:28 nemo_logging:393] cuda=False, using CPU for eigen decomposition. This might slow down the clustering process.\n",
      "clustering: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-22 13:53:28 nemo_logging:381] Outputs are saved in /Users/lucasjackson/Workspace/tensorlake/indexify-extractors/audio/whisper-diarization/temp_outputs directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2024-03-22 13:53:28 nemo_logging:393] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-22 13:53:28 nemo_logging:381] Loading embedding pickle file of scale:0 at /Users/lucasjackson/Workspace/tensorlake/indexify-extractors/audio/whisper-diarization/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
      "[NeMo I 2024-03-22 13:53:28 nemo_logging:381] Loading embedding pickle file of scale:1 at /Users/lucasjackson/Workspace/tensorlake/indexify-extractors/audio/whisper-diarization/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
      "[NeMo I 2024-03-22 13:53:28 nemo_logging:381] Loading embedding pickle file of scale:2 at /Users/lucasjackson/Workspace/tensorlake/indexify-extractors/audio/whisper-diarization/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
      "[NeMo I 2024-03-22 13:53:28 nemo_logging:381] Loading embedding pickle file of scale:3 at /Users/lucasjackson/Workspace/tensorlake/indexify-extractors/audio/whisper-diarization/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
      "[NeMo I 2024-03-22 13:53:28 nemo_logging:381] Loading embedding pickle file of scale:4 at /Users/lucasjackson/Workspace/tensorlake/indexify-extractors/audio/whisper-diarization/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
      "[NeMo I 2024-03-22 13:53:28 nemo_logging:381] Loading cluster label file from /Users/lucasjackson/Workspace/tensorlake/indexify-extractors/audio/whisper-diarization/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
      "[NeMo I 2024-03-22 13:53:28 nemo_logging:381] Filtered duration for loading collection is 0.000000.\n",
      "[NeMo I 2024-03-22 13:53:28 nemo_logging:381] Total 1 session files loaded accounting to # 1 audio clips\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 33.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-22 13:53:28 nemo_logging:381]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
      "[NeMo I 2024-03-22 13:53:28 nemo_logging:381] Number of files to diarize: 1\n",
      "[NeMo I 2024-03-22 13:53:28 nemo_logging:381] Number of files to diarize: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2024-03-22 13:53:28 nemo_logging:393] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-22 13:53:28 nemo_logging:381] Number of files to diarize: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-03-22 13:53:28 nemo_logging:393] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-22 13:53:28 nemo_logging:381] Number of files to diarize: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-03-22 13:53:28 nemo_logging:393] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-22 13:53:28 nemo_logging:381]   \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "from nemo.collections.asr.models.msdd_models import NeuralDiarizer\n",
    "from helpers import create_config\n",
    "\n",
    "# convert audio to mono for NeMo combatibility\n",
    "sound = AudioSegment.from_file(vocal_target).set_channels(1)\n",
    "ROOT = os.getcwd()\n",
    "temp_path = os.path.join(ROOT, \"temp_outputs\")\n",
    "os.makedirs(temp_path, exist_ok=True)\n",
    "sound.export(os.path.join(temp_path, \"mono_file.wav\"), format=\"wav\")\n",
    "\n",
    "# Initialize NeMo MSDD diarization model\n",
    "msdd_model = NeuralDiarizer(cfg=create_config(temp_path)).to(params.get(\"device\"))\n",
    "msdd_model.diarize()\n",
    "\n",
    "del msdd_model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2580664-245f-47ed-bded-e3136b22f54a",
   "metadata": {},
   "source": [
    "# reading timestamps <> speaker label mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e9ef2a6-dc39-4a16-915d-b52393b17f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import get_words_speaker_mapping, punct_model_langs\n",
    "\n",
    "speaker_ts = []\n",
    "with open(os.path.join(temp_path, \"pred_rttms\", \"mono_file.rttm\"), \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line_list = line.split(\" \")\n",
    "        s = int(float(line_list[5]) * 1000)\n",
    "        e = s + int(float(line_list[8]) * 1000)\n",
    "        speaker_ts.append([s, e, int(line_list[11].split(\"_\")[-1])])\n",
    "\n",
    "wsm = get_words_speaker_mapping(word_timestamps, speaker_ts, \"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a4b8334-8fab-4693-b4a3-0cd3dc0e5f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepmultilingualpunctuation import PunctuationModel\n",
    "import re\n",
    "\n",
    "if language in punct_model_langs:\n",
    "    # restoring punctuation in the transcript to help realign the sentences\n",
    "    punct_model = PunctuationModel(model=\"kredor/punctuate-all\")\n",
    "\n",
    "    words_list = list(map(lambda x: x[\"word\"], wsm))\n",
    "\n",
    "    labled_words = punct_model.predict(words_list)\n",
    "\n",
    "    ending_puncts = \".?!\"\n",
    "    model_puncts = \".,;:!?\"\n",
    "\n",
    "    # We don't want to punctuate U.S.A. with a period. Right?\n",
    "    is_acronym = lambda x: re.fullmatch(r\"\\b(?:[a-zA-Z]\\.){2,}\", x)\n",
    "\n",
    "    for word_dict, labeled_tuple in zip(wsm, labled_words):\n",
    "        word = word_dict[\"word\"]\n",
    "        if (\n",
    "            word\n",
    "            and labeled_tuple[1] in ending_puncts\n",
    "            and (word[-1] not in model_puncts or is_acronym(word))\n",
    "        ):\n",
    "            word += labeled_tuple[1]\n",
    "            if word.endswith(\"..\"):\n",
    "                word = word.rstrip(\".\")\n",
    "            word_dict[\"word\"] = word\n",
    "\n",
    "else:\n",
    "    logging.warning(\n",
    "        f\"Punctuation restoration is not available for {language} language. Using the original punctuation.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ea3ad1-f39d-4e75-bdfd-b194df517357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import get_realigned_ws_mapping_with_punctuation, get_sentences_speaker_mapping\n",
    "\n",
    "wsm = get_realigned_ws_mapping_with_punctuation(wsm)\n",
    "ssm = get_sentences_speaker_mapping(wsm, speaker_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75e83c61-efcf-47ec-a275-34198e4072c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'speaker': 'Speaker 1',\n",
       "  'start_time': 0,\n",
       "  'end_time': 1480,\n",
       "  'text': 'Where does that come from? '},\n",
       " {'speaker': 'Speaker 1',\n",
       "  'start_time': 1680,\n",
       "  'end_time': 4078,\n",
       "  'text': \"Oh, just when he wasn't hate, we just, we don't hate right now. \"},\n",
       " {'speaker': 'Speaker 1',\n",
       "  'start_time': 4560,\n",
       "  'end_time': 6940,\n",
       "  'text': \"But no, really, like, it's not a large sample side. \"},\n",
       " {'speaker': 'Speaker 1',\n",
       "  'start_time': 7080,\n",
       "  'end_time': 9580,\n",
       "  'text': \"James Hardin didn't play at all in the preseason. \"},\n",
       " {'speaker': 'Speaker 0',\n",
       "  'start_time': 9840,\n",
       "  'end_time': 11420,\n",
       "  'text': 'Kenny, stop making excuses for that, man. '},\n",
       " {'speaker': 'Speaker 1',\n",
       "  'start_time': 11720,\n",
       "  'end_time': 15840,\n",
       "  'text': \"No, we evaluate them 20 games in, and you'll tell what they are. \"},\n",
       " {'speaker': 'Speaker 0',\n",
       "  'start_time': 15960,\n",
       "  'end_time': 18988,\n",
       "  'text': 'A team with Kauai, James, Russell, no, no, no way. '},\n",
       " {'speaker': 'Speaker 0',\n",
       "  'start_time': 30640,\n",
       "  'end_time': 30964,\n",
       "  'text': 'I act master. '},\n",
       " {'speaker': 'Speaker 0',\n",
       "  'start_time': 31106,\n",
       "  'end_time': 32320,\n",
       "  'text': 'rhythm of of a music rhythm of a. '}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534c53f5-15f1-4e9e-9ad1-86d13e8296cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
